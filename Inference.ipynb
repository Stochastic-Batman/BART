{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Inference\n",
        "\n",
        "This notebook is the continuation of `train.ipynb`, so if you have not viewed that notebook and have not run the code from there, please do so before you begin this notebook.\n",
        "\n",
        "Again, start with installing:"
      ],
      "metadata": {
        "id": "NPSfez5WxNSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy pillow scikit-learn torch"
      ],
      "metadata": {
        "id": "chmEYdTfxjja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "and imports:"
      ],
      "metadata": {
        "id": "K5GTS2msxonc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import joblib\n",
        "import logging\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "\n",
        "from PIL import Image\n",
        "from BART import BART\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', datefmt='%d/%m/%Y %H:%M:%S')\n",
        "logger = logging.getLogger(\"Batlogger (Inference)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "QCaSIzBBxpSU",
        "outputId": "a088171d-75ee-4bb5-c296-eeb7dea69579"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'BART'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2800225989.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mBART\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasicConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%(asctime)s - %(name)s - %(levelname)s - %(message)s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatefmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%d/%m/%Y %H:%M:%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'BART'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We needed to complete the `infer(path: str, model_path: str, is_dir: bool = True) -> None` method, which restores the label encoder from `train.ipynb`, recreates the model, and performs inference. If we want to run inference on a single image, we can pass it via the command line (not possible in the Jupyter Notebook environment) as:\n",
        "\n",
        "`python inference.py IMAGE_NAME.jpg`\n",
        "\n",
        "Alternatively, if all images are located in the `inference_images/` folder (either added manually or automatically - `train.py` also saves 20% of its data into this folder for testing purposes), we can simply run:\n",
        "\n",
        "`python inference.py`\n",
        "\n",
        "In both cases, the result is saved in `results.json`:"
      ],
      "metadata": {
        "id": "TAEFQP3ZxyZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def infer(path: str, model_path: str, is_dir: bool = True) -> None:\n",
        "    label_encoder = joblib.load('label_encoder.joblib')\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = BART(num_classes=len(label_encoder.classes_))\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    results: dict[str, str] = {}\n",
        "\n",
        "    if is_dir:\n",
        "        files = [(f, os.path.join(path, f)) for f in sorted(os.listdir(path)) if f.lower().endswith('.jpg')]\n",
        "    else:\n",
        "        files = [(os.path.basename(path), path)]\n",
        "\n",
        "    for f, p in files:\n",
        "        with Image.open(p) as imag:\n",
        "            img_array = np.array(imag.resize((128, 128)))\n",
        "\n",
        "        img = torch.tensor(img_array, dtype=torch.float32).permute(2, 0, 1) / 255.0\n",
        "        # During training DataLoader automatically creates batches to get shape (BS_size, C, H, W),\n",
        "        # but during inference for a single image we only have (C, H, W), so we need to add batch dimension\n",
        "        img = img.unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            class_idx = torch.max(model(img), 1)[1].item()\n",
        "\n",
        "        results[f] = label_encoder.inverse_transform([class_idx])[0]\n",
        "\n",
        "    with open('results.json', 'w') as file:\n",
        "        json.dump(results, file, indent=4)\n",
        "\n",
        "    logger.info(f\"Saved predictions for {len(results)} images to results.json\")"
      ],
      "metadata": {
        "id": "Kk4QapTFxtUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the method above like this:"
      ],
      "metadata": {
        "id": "dYJw-wZ7zQug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "infer(path='inference_images', model_path='BART-10M.pth', is_dir=True)"
      ],
      "metadata": {
        "id": "UExOKtmYzQVR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}